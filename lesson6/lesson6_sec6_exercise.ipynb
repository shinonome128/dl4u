{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson6 ニューラルネットに画像を生成させよう\n",
    "\n",
    "## 目次\n",
    "\n",
    "- Section6 ケーススタディ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "近年では様々なGANのモデルが提案されており、例えば[hindupuravinash/the-gan-zoo](https://github.com/hindupuravinash/the-gan-zoo)のGithubのレポジトリではたくさんのGANのモデルが紹介されています。ここでは、GANを用いた応用事例の一部を紹介をします。\n",
    "\n",
    "紹介する応用事例を参考に自分だったらGANを使ってどのようなことが出来るか考えてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. テキストから画像生成\n",
    "2. 画像の編集\n",
    "3. 欠損補完\n",
    "4. ドメイン変換\n",
    "5. バーチャル試着"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. テキストから画像生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前章では画像からキャプションを生成しました。GANを使うことでその逆にあたるテキストから画像の生成を行うことが出来ます。\n",
    "\n",
    "以下の例はStackGANと呼ばれるGANによって、テキストを与えてそれに対応する画像を生成する例です。テキストに対応した画像が生成出来ていることが分かります。\n",
    "\n",
    "[StackGAN: Text to Photo-realistic Image Synthesis\n",
    "with Stacked Generative Adversarial Networks](https://arxiv.org/pdf/1612.03242.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/stackgan.png'>\n",
    "引用: [StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks](https://arxiv.org/pdf/1612.03242.pdf) Figure3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "StackGANは与えられた説明文とノイズから低解像度の画像を出力する「Stage-Ⅰ」と、Stage-Iの出力と説明文から高解像度の画像を出力する「Stage-Ⅱ」の2つのステージからなるGANです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 類似の研究\n",
    "    - [Generative Adversarial Text to Image Synthesis](https://arxiv.org/pdf/1605.05396.pdf)\n",
    "    - [TAC-GAN – Text Conditioned Auxiliary Classifier Generative Adversarial Network](https://arxiv.org/pdf/1703.06412.pdf)\n",
    "    - [StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks](https://arxiv.org/pdf/1710.10916.pdf)\n",
    "    - [AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks](https://arxiv.org/pdf/1711.10485.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 画像の編集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "演習でおこなったConditional GANでは、Generatorにノイズと条件付けの数字の情報を入力として与えました。画像を入力としてそれを任意の条件に画像を編集することも出来ます。\n",
    "\n",
    "以下の例はIC-GANと呼ばれるGANです。一番左の元々の画像を様々な条件に編集した画像を出力出来ていることが分かります。\n",
    "\n",
    "[Invertible Conditional GANs for image editing](https://arxiv.org/abs/1611.06355)\n",
    "\n",
    "conditionalな変数に対してもEncoderを用意したことで画像の属性のコントロールが出来るようになったところに特徴があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/icgan.png' width='80%'>\n",
    "引用: [Invertible Conditional GANs for image editing](https://arxiv.org/pdf/1611.06355.pdf) Figure6 (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他にも以下のような人物の顔画像から年齢を変化させた画像を生成するGANもあります。\n",
    "\n",
    "[FACE AGING WITH CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS](https://arxiv.org/pdf/1702.01983.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/faceaginggan.png' width='50%'>\n",
    "引用: [FACE AGING WITH CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS](https://arxiv.org/pdf/1702.01983.pdf) Fig.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 類似の研究\n",
    "    - [Age Progression/Regression by Conditional Adversarial Autoencoder](https://arxiv.org/pdf/1702.08423.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雨や雪を写真から消すようなGANもあります。\n",
    "[Image De-raining Using a Conditional Generative Adversarial Network](https://arxiv.org/pdf/1701.05957.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 欠損補完"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像の欠損部分を補完することもGANで行われています。以下のように欠損した画像を入力にして欠損部分が補完した画像を出力することが出来ます。\n",
    "\n",
    "[Semantic Image Inpainting with Deep Generative Models](https://arxiv.org/pdf/1607.07539.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../figures/inpainting.png' width='30%'>\n",
    "引用: [Semantic Image Inpainting with Deep Generative Models](https://arxiv.org/pdf/1607.07539.pdf) Figure.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ドメイン変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通称Pix2Pixと呼ばれる画像のドメイン変換も行われています。　( [Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/pdf/1611.07004.pdf) )\n",
    "\n",
    "以下の画像のようにセグメンテーションの画像から写真のような画像に変換したり、線画に着色したりと様々な用途に利用することが出来ます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/image-to-image.png' width='80%'>\n",
    "引用: [Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/pdf/1611.07004.pdf) Figure.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の実際にdemoを使って遊んでみることが出来ます。\n",
    "\n",
    "[Image-to-Image Demo](https://affinelayer.com/pixsrv/)\n",
    "\n",
    "Generatorのネットワークは　Skip connection付きのEncoder-DecoderモデルのU-Netと呼ばれる構造となっています。\n",
    "汎用的に様々なタスクに応用出来るためアプリケーションとしての応用を考えやすいと思います。\n",
    "\n",
    "詳しい内容は以下のスライドが参考になります。\n",
    "\n",
    "[[DL輪読会]Image-to-Image Translation with Conditional Adversarial Networks](https://www.slideshare.net/DeepLearningJP2016/dlimagetoimage-translation-with-conditional-adversarial-networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pix2Pixの学習には対となるデータセットが必要となりますが、対となるデータセットを集めることが難しかったり、そもそも困難であったりすることがあります。\n",
    "\n",
    "Cycle GAN ( [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/pdf/1703.10593.pdf) )と呼ばれるGANでは、対となるデータセットがなくても、各ドメインの画像をそれぞれ用意するだけで学習を行うことが可能です。\n",
    "\n",
    "以下のように、シマウマの画像から馬の画像に変換したりその逆を行ったりすることが可能です。また、写真をモネやゴッホ風の絵に変換するなども出来ます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/cyclegan.png' width='80%'>\n",
    "引用: [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/pdf/1703.10593.pdf) Figure.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詳しい内容は以下のスライドが参考になります。\n",
    "\n",
    "[[DL輪読会]Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://www.slideshare.net/DeepLearningJP2016/dlharmonic-networks-deep-translation-and-rotation-equivariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. バーチャル試着"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファッションの分野では、GANを用いて画像内の人物の服の着せ替えも行われています。例えば、[Artificial intelligence can say yes to the dress](https://qz.com/1090267/artificial-intelligence-can-now-show-you-how-those-pants-will-fit/) にブログ記事として紹介されています。\n",
    "\n",
    "ECサイトでよく見かけるモデルの写真を自動生成出来るようになればコスト削減になりますし、自分の写真を着たい服に着せ替えるようなバーチャル試着が可能になればオンライン上の購買体験の質を向上させることが出来るようになります。このように、GANを用いて様々な分野に大きなインパクトのあるアプリケーションが提案出来るかもしれません。\n",
    "\n",
    "公開されているGANでは、CA-GANというGANが着せ替えを行うGANもあります。([The Conditional Analogy GAN: Swapping Fashion Articles on People Images](https://arxiv.org/pdf/1709.04695.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/cagan.png' width='50%'>\n",
    "引用: [The Conditional Analogy GAN: Swapping Fashion Articles on People Images](https://arxiv.org/pdf/1709.04695.pdf) Figure.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
