{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson6 ニューラルネットに画像を生成させよう\n",
    "\n",
    "## 目次\n",
    "\n",
    "- Section3 テクニック・発展的内容\n",
    "  - 3.1 Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTのロードと表示のための関数です。後で使うので読み込んでおいて下さい。\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load_mnist(dim=3, data='mnist'):\n",
    "    img_rows, img_cols = 28, 28\n",
    "    \n",
    "    if data == 'mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    else:\n",
    "        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    \n",
    "    if dim == 3:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows*img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows*img_cols)\n",
    "        \n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    y_train = np.eye(10)[y_train]\n",
    "    y_test = np.eye(10)[y_test]\n",
    "    \n",
    "    return  x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def plot_mnist_conditional(n_ex=10,dim=(2, 5), figsize=(8,4), labels=range(10)):\n",
    "    noise = np.random.uniform(0,1,size=[n_ex,100])\n",
    "    label_batch = np.eye(10)[np.arange(10)]\n",
    "    generated_images = generator.predict([noise, label_batch])\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1], i+1)\n",
    "        img = generated_images[i,:,:, 0]\n",
    "        plt.imshow(img, cmap='binary')\n",
    "        plt.title(labels[i])\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section1では生成する画像のコントロールが出来ませんでした。つまり、数字の1が生成したくてもGeneratorにそうするように制御することが出来ませんでした。\n",
    "\n",
    "Section3ではラベルを指定することで任意の数字を生成出来るように制御出来るConditional GANを実装して、ニューラルネットに好きな数字を生成させてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Conditional GANとは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的にはSection1で作成したネットワークと同じです。違いはGeneratorとDiscriminatorのそれぞれにラベルに対応した数字のラベルも入力するところです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/gan2.png' alt='gan_2'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section1のGANとの違いはランダムノイズに数字のラベル情報を結合しているところです。\n",
    "\n",
    "以下の実装のようにラベル情報もGeneratorのinputに追加されています。\n",
    "\n",
    "つまり、要素の100のノイズと要素10のone-hotベクトルのラベル情報を入力として、サイズ28x28でチャンネル1の画像を出力にしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, concatenate, Reshape, Dense, Activation, Conv2D, UpSampling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def Generator():\n",
    "    \n",
    "    nch=200\n",
    "    ## 1章のGANとの違い ##\n",
    "    # ランダムなノイズ\n",
    "    model_input = Input(shape=[100])\n",
    "    # 0~9のどの数字の画像かのラベル情報\n",
    "    cond = Input(shape=[10])\n",
    "    # 上記2つを結合する\n",
    "    cond_input = concatenate([model_input, cond], axis=-1) \n",
    "    \n",
    "    x = Dense(nch*14*14, kernel_initializer='glorot_normal')(cond_input) # 110 -> 200*14*14\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Reshape( [14, 14, nch] )(x) # 200*14*14 -> 14x14x200\n",
    "    x = UpSampling2D(size=(2, 2))(x) # 14x14x200 -> 28x28x200\n",
    "    x = Conv2D(int(nch/2), (3, 3), padding='same', kernel_initializer='glorot_uniform')(x) # 28x28x200 -> 28x28x100\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(int(nch/4), (3, 3), padding='same', kernel_initializer='glorot_uniform')(x) # 28x28x100 -> 28x28x50\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(1, (1, 1), padding='same', kernel_initializer='glorot_uniform')(x) # 28x28x50 -> 28x28x1\n",
    "    model_output = Activation('sigmoid')(x)\n",
    "    model = Model([model_input, cond], model_output)\n",
    "    # model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section1のGANとの違いは画像に加えて、数字のラベル情報を結合しているところです。\n",
    "\n",
    "以下の実装のようにラベル情報もDiscriminatorのinputに追加されています。\n",
    "\n",
    "入力としてはサイズ28x28でチャンネル1の画像と要素10のone-hotベクトルのラベル情報を入力にして、その画像がデータセットにある本物データかどうかを2値で出力します。\n",
    "\n",
    "注意するのは画像とラベル情報を結合するところです。ラベル情報を28x28x10にreshapeしているところがポイントです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、実装に関して今回LambdaというLayerを利用するので説明をします。\n",
    "\n",
    "Kerasでネットワークを構築するときにLayerに定義された層以外を使いたいときは、Lambdaというlayerを用いてラップする必要があります。\n",
    "例えば、値を2乗するLayerを追加するときは以下のようにしてLambdaでラップします。\n",
    "\n",
    "```\n",
    "Lambda(lambda x: x ** 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, concatenate, Lambda, Reshape, Dense, Dropout, Flatten, LeakyReLU, Conv2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def Discriminator(shape, dropout_rate=0.25, opt=Adam(lr=1e-4)):\n",
    "    \n",
    "    ## 1章のGANとの違い ##\n",
    "    model_input = Input(shape=shape)\n",
    "    cond = Input(shape=[10])\n",
    "    \n",
    "    # ここでラベル情報をreshape\n",
    "    cond_reshape = Reshape( [1, 1, 10] )(cond) # 1x1x10\n",
    "    cond_reshape = Lambda(lambda x: K.ones([28, 28, 10])*x)(cond_reshape) # 1x1x10 -> 28x28x10\n",
    "    cond_input = concatenate([model_input, cond_reshape], axis=-1) # 28x28x11\n",
    "    \n",
    "    x = Conv2D(256, (5, 5), padding = 'same', kernel_initializer='glorot_uniform', strides=(2, 2))(cond_input) # 28x28x11 -> 14x14x256\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Conv2D(512, (5, 5), padding = 'same', kernel_initializer='glorot_uniform', strides=(2, 2))(x) # 14x14x256 -> 7x7x512\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Flatten()(x) # 7x7x512 -> 7*7*512\n",
    "    x = Dense(1024)(x) # 7*7*512 -> 1024\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dense(512)(x) # 1024 -> 512\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dense(256)(x) # 512 -> 256\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    model_output = Dense(2,activation='softmax')(x) # 256 -> 2\n",
    "    model = Model([model_input, cond], model_output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "    # model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 GANの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習自体はSection1のGANとほとんど同じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def combined_network(generator, discriminator, opt=Adam(lr=1e-3)):\n",
    "    gan_input = Input(shape=[100])\n",
    "    cond = Input(shape=[10])\n",
    "    x = generator([gan_input, cond])\n",
    "    gan_output = discriminator([x, cond])\n",
    "    model = Model([gan_input, cond], gan_output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "    # model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(step=3000, BATCH_SIZE=128):\n",
    "\n",
    "    for e in tqdm(range(step)):  \n",
    "        \n",
    "        image_indexes = np.random.randint(0,X_train.shape[0],size=BATCH_SIZE)\n",
    "        image_batch = X_train[image_indexes,:,:,:]  \n",
    "        label_batch = y_train[image_indexes]  \n",
    "        noise_gen = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n",
    "        generated_images = generator.predict([noise_gen, label_batch])\n",
    "        \n",
    "        make_trainable(discriminator,True)\n",
    "        \n",
    "        X = np.concatenate((image_batch, generated_images))\n",
    "        y = np.zeros([2*BATCH_SIZE,2])\n",
    "        y[:BATCH_SIZE,1] = 1\n",
    "        y[BATCH_SIZE:,0] = 1\n",
    "        \n",
    "        label_batch = np.concatenate((label_batch, label_batch))\n",
    "        \n",
    "        \n",
    "        discriminator.train_on_batch([X, label_batch], y)\n",
    "        \n",
    "        make_trainable(discriminator,False)\n",
    "    \n",
    "        noise_tr = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n",
    "        y2 = np.zeros([BATCH_SIZE,2])\n",
    "        y2[:,1] = 1\n",
    "        \n",
    "        label_batch2 = np.random.randint(0, 10, size=BATCH_SIZE)\n",
    "        label_batch2 = np.eye(10)[label_batch2]\n",
    "             \n",
    "        GAN.train_on_batch([noise_tr, label_batch2], y2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5 MNISTによる学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network \n",
    "X_train, _, y_train, _ = load_mnist()\n",
    "generator = Generator()\n",
    "discriminator = Discriminator(X_train.shape[1:])\n",
    "make_trainable(discriminator, False)\n",
    "GAN = combined_network(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6 手書き文字の生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それではニューラルネットに画像を生成させてみましょう。順に0~9が並ぶことが確認出来ると思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_mnist_conditional()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkクイズ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 問題1\n",
    "    - 今回実装したConditional GANに関して、次の選択肢から不適切なものを一つ選びなさい\n",
    "- 選択肢\n",
    "    1. Conditional GANは生成する画像の数字を制御出来る。\n",
    "    2. Generatorにラベルyを付与する。\n",
    "    3. Discriminatorにラベルyを付与する。\n",
    "    4. 潜在変数zを変えると生成する画像の数字も変わる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 問題2\n",
    "    - Conditional GANとして最も適切なものを一つ選びなさい\n",
    "-  選択肢\n",
    "    1. $\\underset{G}{\\min}\\underset{D}{\\max}V(D, G) = E_{x{\\sim}p_{data}(x)}[\\log D(x|y)] +E_{z{\\sim}p_{data}(z)}[\\log(1-D(G(z|y)))]$\n",
    "    2. $\\underset{G}{\\min}\\underset{D}{\\max}V(D, G) = E_{x{\\sim}p_{data}(x)}[\\log D(x)] +E_{z{\\sim}p_{data}(z)}[\\log(1-D(G(z)))]$\n",
    "    3. $\\underset{G}{\\min}\\underset{D}{\\max}V(D, G) = E_{x{\\sim}p_{data}(x)}[\\log D(x|y)] +E_{z{\\sim}p_{data}(z)}[\\log(1-D(G(z)))]$\n",
    "    4. $\\underset{G}{\\min}\\underset{D}{\\max}V(D, G) = E_{x{\\sim}p_{data}(x)}[\\log D(y)] +E_{z{\\sim}p_{data}(z)}[\\log(1-D(G(z|y)))]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
