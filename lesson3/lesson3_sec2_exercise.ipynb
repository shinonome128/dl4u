{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson3 系列データで分類・予測させてみよう（RNN, LSTM）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目次\n",
    "\n",
    "- Section1 Checkクイズの解答\n",
    "- Section2. 実装①\n",
    "    - 2.0 データの用意\n",
    "    - 2.1 モデル構築\n",
    "    - 2.2 モデルの学習\n",
    "    - 2.3 モデルによる予測\n",
    "    - 2.4 モデルの可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section1 Checkクイズの解答\n",
    "\n",
    "問題1: 2, 問題2: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section2 実装①\n",
    "\n",
    "ここでは、以下のページのECGによる波形データセットECG5000をRNNで学習し、分類を行ってみましょう。\n",
    "\n",
    "http://timeseriesclassification.com/description.php?Dataset=ECG5000\n",
    "\n",
    "このデータセットは、ECGの計測値140時点分とその系列に対する分類（1～5）で1データとなっており、全体で5000データが含まれています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 データの用意\n",
    "\n",
    "**ここで利用するデータセットはリポジトリに含まれていません。**\n",
    "\n",
    "上記リンク先のページ中段にある \"Download this dataset\" をクリックの上、ご自身でダウンロードして頂くようお願い致します。\n",
    "\n",
    "ダウンロードしたデータセットはdataフォルダ内に配置していただく必要があります。\n",
    "\n",
    "データセットの配置が完了したら、まずは配置したデータセットの読み込みを行いましょう。\n",
    "\n",
    "arffという形式で保存されているため、`scipy.io.loadarff`関数でロードします。\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.arff.loadarff.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "\n",
    "dataset, meta = arff.loadarff('data/ECG5000.arff')\n",
    "\n",
    "ds = np.asarray(dataset.tolist(), dtype=np.float32)\n",
    "x_dataset = ds[:, :140]\n",
    "y_dataset = np.asarray(ds[:,-1].tolist(), dtype=np.int8)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に表示してみて、様子を確認しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 10\n",
    "print(y_dataset[:N])\n",
    "obj = plt.plot(x_dataset[:N].T)\n",
    "plt.legend(obj, [str(n) for n in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確かに、分類結果が異なる3,7番はt=100付近でピークを持たないことが見て取れます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いて、データセットを訓練用とテスト用に分割します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データとテストデータを分割（＋データの整形）\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_dataset[:,:,np.newaxis], to_categorical(y_dataset), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 モデル構築\n",
    "\n",
    "ここでは、先程紹介したSimpleRNNを使用してモデルを構築します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, SimpleRNN\n",
    "\n",
    "hid_dim = 10\n",
    "\n",
    "# SimpleRNNにDenseを接続し、分類\n",
    "model = Sequential()\n",
    "\n",
    "model.add(SimpleRNN(hid_dim, input_shape=x_train.shape[1:])) # input_shape=(系列長T, x_tの次元), output_shape=(units(=hid_dim),)\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 モデルの学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=50, batch_size=100, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 モデルによる分類精度の評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性能評価\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('test_loss:', score[0])\n",
    "print('test_acc:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 モデルの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
