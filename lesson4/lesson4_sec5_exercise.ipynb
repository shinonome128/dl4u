{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson4 ニューラル翻訳モデルを作ってみよう（Seq2Seq, Attention）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目次\n",
    "\n",
    "- Section5 ケーススタディ\n",
    "    - 5.1 文書要約・対話システム\n",
    "    - 5.2 音声・画像への適用\n",
    "    - 5.3 スケッチの自動描画"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section5 ケーススタディ\n",
    "\n",
    "ここでは、今回扱ったSeq2Seq with attentionモデルの翻訳以外への応用例に関する論文を紹介しておきたいと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 文書要約・対話システム\n",
    "\n",
    "文字列を扱うものでは、翻訳以外にも代表的なタスクとして文書要約や対話システムがあります。\n",
    "\n",
    "まず、こちらの論文ではSeq2Seqモデルやその発展形によって、**文書要約タスク**（特に見出し生成や短文生成タスク）の精度向上を行っています。\n",
    "\n",
    "R. Nallapati, B. Zhou, C. dos Santos, C. Gulcehre and B. Xiang, \"Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond,\" 2016. ( https://arxiv.org/abs/1602.06023 )\n",
    "![summarization](figures/summarization.png)\n",
    "\n",
    "この論文ではSeq2Seqモデルによって、テキスト会話の**対話システム**を構築し、質問の解決が可能な例を示しています。\n",
    "\n",
    "O. Vinyals and Q.V. Le, \"A Neural Conversational Model,\" 2015. ( https://arxiv.org/abs/1506.05869 )  \n",
    "![chat](figures/case_chat.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 音声・画像への適用\n",
    "\n",
    "Seq2Seqモデルは文字だけでなく、音声や画像を扱うことも可能です。事例としては、次の**読唇術**を行うモデルが存在します。\n",
    "\n",
    "J.S. Chung, A. Senior, O. Vinyals, A. Zisserman, \"Lip Reading Sentences in the Wild,\" 2016. ( https://arxiv.org/abs/1611.05358 )\n",
    "\n",
    "この論文では、'Watch, Listen, Attend and Spell' (WLAS) networkという、口の画像と音声を各々エンコード、文字としてデコードするモデルを提案し、カリキュラム学習によって高精度の読唇術を実現しています。\n",
    "\n",
    "<img src=\"figures/Lip.jpg\" width=50%>\n",
    "\n",
    "また、よりポピュラーなタスクとしては**音声認識タスク**が挙げられますが、2016年にはMicrosoft Researchの研究者が対話型の音声認識タスクで、LSTMを使ったモデルで人間と同等の認識率を達成しました。\n",
    "\n",
    "W. Xiong, et al., \"Achieving Human Parity in Conversational Speech Recognition,\" 2016. ( https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/ms_parity.pdf )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 スケッチの自動描画\n",
    "\n",
    "Seq2SeqにLesson6で紹介するVAEと呼ばれる生成モデルを組み合わせることで、手描きイラストの予測モデル構築したのが次の論文です。\n",
    "\n",
    "D. Ha, D. Eck, \"A Neural Representation of Sketch Drawings,\" 2017 ( https://arxiv.org/abs/1704.03477 )\n",
    "\n",
    "この論文では、Bidirectional RNNのエンコーダ部とRNNのデコーダ部に加えて潜在変数をVAEでモデル化しています。\n",
    "\n",
    "また、スケッチをピクセル画像としてではなく、線の集まりとして入力することで一貫性を高めているという特徴があります。\n",
    "\n",
    "<img src=\"figures/sketch_rnn.jpg\" width=80%>\n",
    "\n",
    "この論文で提案されたsketch-rnnモデルによる、スケッチの自動描画は下記のサイトで実際に試す事が可能です。\n",
    "\n",
    "https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html\n",
    "\n",
    "![demo](https://magenta.tensorflow.org/assets/sketch_rnn_demo/img/multi_sketch_mosquito.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
